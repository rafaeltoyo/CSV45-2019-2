{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa os pacotes necessários\n",
    "import numpy as np\n",
    "import os, cv2, random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import np_utils\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funções de leitura e preparação das imagens\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))    \n",
    "    return data\n",
    "\n",
    "def show_cats_and_dogs(idx):\n",
    "    cat = read_image(train_cats[idx])\n",
    "    dog = read_image(train_dogs[idx])\n",
    "    pair = np.concatenate((cat, dog), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "    \n",
    "# dois exemplos de descritores. Você deve criar outros mais robustos.\n",
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):     \n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    #image = cv2.imread(image_file)        \n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "        [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'kaggle/cifar-10/train'\n",
    "TRAIN_LABELS_DIR = 'kaggle/cifar-10/trainLabels.csv'\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "NIM = 1000\n",
    "\n",
    "image_paths = os.listdir(TRAIN_DIR)\n",
    "\n",
    "train_images = [read_image(TRAIN_DIR + \"/\" + i) for i in image_paths]\n",
    "train_labels = pd.read_csv(TRAIN_LABELS_DIR)\n",
    "\n",
    "#num_classes = 10\n",
    "#y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "#y_test = np_utils.to_categorical(y_test,num_classes)\n",
    "\n",
    "# considera apenas NIM imagens. Para o dataset completo, desconsiderar.\n",
    "# random.shuffle(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 50000\n",
      "Processed 1000 of 50000\n",
      "Processed 2000 of 50000\n",
      "Processed 3000 of 50000\n",
      "Processed 4000 of 50000\n",
      "Processed 5000 of 50000\n",
      "Processed 6000 of 50000\n",
      "Processed 7000 of 50000\n",
      "Processed 8000 of 50000\n",
      "Processed 9000 of 50000\n",
      "Processed 10000 of 50000\n",
      "Processed 11000 of 50000\n",
      "Processed 12000 of 50000\n",
      "Processed 13000 of 50000\n",
      "Processed 14000 of 50000\n",
      "Processed 15000 of 50000\n",
      "Processed 16000 of 50000\n",
      "Processed 17000 of 50000\n",
      "Processed 18000 of 50000\n",
      "Processed 19000 of 50000\n",
      "Processed 20000 of 50000\n",
      "Processed 21000 of 50000\n",
      "Processed 22000 of 50000\n",
      "Processed 23000 of 50000\n",
      "Processed 24000 of 50000\n",
      "Processed 25000 of 50000\n",
      "Processed 26000 of 50000\n",
      "Processed 27000 of 50000\n",
      "Processed 28000 of 50000\n",
      "Processed 29000 of 50000\n",
      "Processed 30000 of 50000\n",
      "Processed 31000 of 50000\n",
      "Processed 32000 of 50000\n",
      "Processed 33000 of 50000\n",
      "Processed 34000 of 50000\n",
      "Processed 35000 of 50000\n",
      "Processed 36000 of 50000\n",
      "Processed 37000 of 50000\n",
      "Processed 38000 of 50000\n",
      "Processed 39000 of 50000\n",
      "Processed 40000 of 50000\n",
      "Processed 41000 of 50000\n",
      "Processed 42000 of 50000\n",
      "Processed 43000 of 50000\n",
      "Processed 44000 of 50000\n",
      "Processed 45000 of 50000\n",
      "Processed 46000 of 50000\n",
      "Processed 47000 of 50000\n",
      "Processed 48000 of 50000\n",
      "Processed 49000 of 50000\n"
     ]
    }
   ],
   "source": [
    "rawImages = []\n",
    "descHist = []\n",
    "\n",
    "count = len(train_images)\n",
    "\n",
    "for i, image in enumerate(train_images):\n",
    "    pixels = image_to_feature_vector(image)\n",
    "    histogram = extract_color_histogram(image)\n",
    "    \n",
    "    rawImages.append(pixels)\n",
    "    descHist.append(histogram)\n",
    "        \n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label_airplane', 'label_automobile', 'label_bird', 'label_cat',\n",
      "       'label_deer', 'label_dog', 'label_frog', 'label_horse', 'label_ship',\n",
      "       'label_truck'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "labels = list(train_labels.label.unique())\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def one_hot(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode \n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df2 = pd.concat([df, dummies], axis=1)\n",
    "    return df2\n",
    "\n",
    "df2 = one_hot(train_labels,['label'])\n",
    "del df2['label']\n",
    "del df2['id']\n",
    "\n",
    "print(df2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "did\n"
     ]
    }
   ],
   "source": [
    "#Avalia o primeiro descritor: as imagens raw\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(rawImages, df2, test_size=0.10, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),    \n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    print(\"did\")\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avalia o segundo descritor: color histogram\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(descHist, labels, test_size=0.25, random_state=42)\n",
    "classifiers = [KNeighborsClassifier(17), DecisionTreeClassifier(), GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avalia a combinação dos dois primeiros descritores!\n",
    "\n",
    "#ATENÇÃO: ESTE É APENAS UM CÓDIGO EXEMPLO. VOCÊ DEVE DESENVOLVER\n",
    "#DESCRITORES MAIS ROBUSTOS, BEM COMO EXPLORAR MELHOR AS MÉTRICAS\n",
    "#DE AVALIAÇÃO (MATRIZ DE CONFUSÃO, ETC)\n",
    "\n",
    "trainAux = np.hstack((descHist, rawImages))\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(trainAux, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),    \n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
